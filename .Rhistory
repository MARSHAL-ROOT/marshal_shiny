}, error = function(e) {
})
}
genes
cat(genes, file="~/Desktop/genes_2017.txt")
source('~/Desktop/wordcloud_plantdirect.R')
install.packages("googlesheets")
library(googlesheets)
gs_ls()
be <- gs_title("twitter_planning")
gs_ws_ls(be)
west <- gs_read(ss=be, ws = "Sheet1", skip=1)
west <- gs_read(ss=be, ws = "Sheet1")
dois <- gs_read(ss=be, ws = "Sheet1")
paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi)
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
library(jsonlite)
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi)
papers <- gs_read(ss=be, ws = "Sheet1")
doi <- papers$doi[1]
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
doc
doc$message$author
doc$message$author[1]
doc$message$author[2]
authors <- NULL
for(doi in papers$doi){
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
authors <- rbind(authors,doc$message$author)
}
authors
authors <- NULL
for(doi in papers$doi){
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
authors <- rbind(authors,doc$message$author[,c(1,2)])
}
authors
doc
doc$message$author[,c(1,2)]
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
doi
authors <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
authors <- rbind(authors,doc$message$author[,c(1,2)])
}, warning = function(w) {
}, error = function(e) {
})
}
authors$id <- paste(authors$given, authors$family)
length(unique(authors$id))
doi
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
doc
twitters <- 0
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
twitters <- twitters + doc$cited_by_tweeters_count
}, warning = function(w) {
}, error = function(e) {
})
}
twitters
twitters <- 0
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
twitters <- twitters + doc$cited_by_tweeters_count
print(doc$cited_by_tweeters_count)
}, warning = function(w) {
}, error = function(e) {
})
}
almetrics <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
almetrics <- rbind(almetrics, data.frame(twitter = doc$cited_by_tweeters_count,
score = doc$score))
}, warning = function(w) {
}, error = function(e) {
})
}
almetrics
almetrics <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score))
}, warning = function(w) {
}, error = function(e) {
})
}
almetrics
mean(almetrics$twitter)
mean(almetrics$score)
mode(almetrics$score)
sum(almetrics$score)
sum(almetrics$twitter)
authors <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.crossref.org/v1/works/http://dx.doi.org/',doi))
authors <- rbind(authors,doc$message$author[,c(1,2,3)])
}, warning = function(w) {
}, error = function(e) {
})
}
authors
doc$message$author[,3]
countries <- read_csv("~/Desktop/countries.csv")
co <- countries$name[1]
co
grepl(co, authors$affiliation)
if(grepl(co, authors$affiliation)) print("true")
test <- grepl(co, authors$affiliation)
countries$name[test]
for(co in countries$name){
test <- grepl(co, authors$affiliation)
countries$name[test]
}
for(co in countries$name){
test <- grepl(co, authors$affiliation)
print(countries$name[test])
}
test[test]
length(test[test])
for(co in countries$name){
test <- grepl(co, authors$affiliation)
if(length(test[test]) > 0)print(co)
}
country <- NULL
for(co in countries$name){
test <- grepl(co, authors$affiliation)
if(length(test[test]) > 0) country <- c(country, co)
}
country
length(unique(country))
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
almetrics <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = doc$readers_count,
blog = doc$cited_by_feeds_count,
news = doc$cited_by_msm_count))
}, warning = function(w) {
}, error = function(e) {
})
}
sum(almetrics$reader)
almetrics
almetrics <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = doc$readers_count,
blog = doc$cited_by_feeds_count,
news = doc$cited_by_msm_count))
}, warning = function(w) {
}, error = function(e) {
})
}
papers$doi
almetrics
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
doc
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = doc$readers_count,
blog = doc$cited_by_feeds_count,
news = doc$cited_by_msm_count))
doc$cited_by_tweeters_count
almetrics
doc$cited_by_tweeters_count,
doc$cited_by_tweeters_count
doc$score
data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = doc$readers_count,
blog = doc$cited_by_feeds_count,
news = doc$cited_by_msm_count)
doc$score
doc$readers_count
doc$cited_by_feeds_count
doc$cited_by_msm_count
max(doc$cited_by_feeds_count, 0)
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = doc$readers_count,
blog = max(doc$cited_by_feeds_count, 0),
news = doc$cited_by_msm_count))
almetrics <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = doc$readers_count,
blog = max(doc$cited_by_feeds_count, 0),
news = doc$cited_by_msm_count))
}, warning = function(w) {
}, error = function(e) {
})
}
almetrics
almetrics <- NULL
for(doi in papers$doi){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',doi))
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = max(doc$readers_count, 0),
blog = max(doc$cited_by_feeds_count, 0),
news = max(doc$cited_by_msm_count, 0)))
}, warning = function(w) {
}, error = function(e) {
})
}
almetrics
sum(almetrics$reader)
sum(almetrics$news)
sum(almetrics$blog)
rs <- yaml.load_file("~/Dropbox/science/outputs/websites/guillaumelobet.github.io/_data/publications.yml")
library(scholar)
library(yaml)
library(stringdist)
rs <- yaml.load_file("~/Dropbox/science/outputs/websites/guillaumelobet.github.io/_data/publications.yml")
i
i <- 2
rs[[i]]
rs[[i]]$doi
almetrics <- NULL
for(i in 2:length(rs)){
tryCatch({
doc = fromJSON(paste0('https://api.altmetric.com/v1/doi/',rs[[i]]$doi))
almetrics <- rbind(almetrics, data.frame(doi = doi,
twitter = doc$cited_by_tweeters_count,
score = doc$score,
reader = max(doc$readers_count, 0),
blog = max(doc$cited_by_feeds_count, 0),
news = max(doc$cited_by_msm_count, 0)))
}, warning = function(w) {
}, error = function(e) {
})
}
almetrics
sum(almetrics$twitter)
sum(almetrics$score)
sum(almetrics$reader)
library(jsonlite)
library(tidyverse)
library(xml2)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(googlesheets)
titles <- ""
abstracts <- ""
genes <- ""
temp1 <- '<div class="article-section__content mainAbstract">\n<h2 class="article-section__header">Abstract</h2>'
for(i in c(8:30)){
print(i)
tryCatch({
# Read and parse HTML file
doc = read_html(paste0('http://onlinelibrary.wiley.com/doi/10.1002/pld3.',i,'/abstract'))
# Find all links
title <- doc %>%
# xml_find_all(".//section") %>%
xml_find_all(".//title")
titles <- paste0(titles, strsplit(as.character(xml_contents(title[[1]])[1]), ' - ')[[1]][1], "\n")
print(strsplit(as.character(xml_contents(title[[1]])[1]), ' - ')[[1]][1])
abst <- doc %>%
# xml_find_all(".//section") %>%
xml_find_all(".//section")
for(j in c(1:length(abst))){
if(!is.na(xml_attr(abst[[j]], "id"))){
if(xml_attr(abst[[j]], "id") == "abstract"){
abstracts <- paste0(abstracts, gsub(temp1, "", as.character(xml_contents(abst[[j]])[1])), "\n")
}
}
}
gen <- doc %>%
xml_find_all(".//section") %>%
xml_find_all(".//em")
for(j in c(1:length(gen))){
genes <- paste0(genes, as.character(xml_contents(gen[[j]])), "\n")
}
}, warning = function(w) {
}, error = function(e) {
})
}
cat(abstracts, file="~/Desktop/abstracts_2017.txt")
cat(titles, file="~/Desktop/titles_2017.txt")
diamonds
load(diamonds)
iris
library(tidyverse)
iris %>%
filter(Species == "virginica")
rs <- iris %>%
filter(Species == "virginica")
rs$Sepal.Length
rs %>%
ggplot(aes(Sepal.Length, Sepal.Width, colour=Species)) +
geom_point()
iris %>%
ggplot(aes(Sepal.Length, Sepal.Width, colour=Species)) +
geom_point()
iris %>%
filter(Species != "viginica") %>%
ggplot(aes(Sepal.Length, Sepal.Width, colour=Species)) +
geom_point()
iris %>%
filter(Species != "virginica") %>%
ggplot(aes(Sepal.Length, Sepal.Width, colour=Species)) +
geom_point()
iris %>%
group_by(Species) %>%
summarize()
iris %>%
group_by(Species) %>%
summarize(mean = mean(Petal.Length))
iris %>%
group_by(Species) %>%
summarize(Petal.Length = mean(Petal.Length))
library(readr)
iris %>%
melt(id=c("Species"))
library(reshape2)
iris %>%
melt(id=c("Species"))
iris %>%
melt(id=c("Species")) %>%
ggplot(aes(Species, variable, colour = Species)) +
geom_boxplot()
iris %>%
melt(id=c("Species")) %>%
ggplot(aes(Species, value, colour = Species)) +
geom_boxplot()
iris %>%
melt(id=c("Species")) %>%
ggplot(aes(Species, value, colour = Species)) +
geom_boxplot() +
facet_grid(~variable)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
library(tidyverse)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
abstracts <- read_text("~/Desktop/live_notes.txt")
abstracts <- read_file("~/Desktop/live_notes.txt")
cleanFun <- function(htmlString) {
htmlString <- gsub("\n", "", htmlString)
htmlString <- gsub("Summary", "", htmlString)
return(gsub("<.*?>", "", htmlString))
}
abstracts <- cleanFun(abstracts)
docs <- Corpus(VectorSource(abstracts))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("div", "<em>", "</em>"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Greens"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Greens"))
docs <- tm_map(docs, removeWords, c("div", "<em>", "</em>", "can"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Greens"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(6, "Blues"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(4, "Blues"))
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Blues"))
rs  <- "~/Desktop/root_data_dicot-2.csv"
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv")
library(tidyverse)
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv")
View(rs)
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv") %>%
select(image, overlap)
rs2  <- read_csv("~/Dropbox/science/outputs/papers/2018-mee_rose_pitfalls/data_dpi/all_root_data.csv")
rs3 <- merge(rs2, rs, by = "image")
View(west)
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv") %>%
select(image, overlap)
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv")
rs2  <- read_csv("~/Dropbox/science/outputs/papers/2018-mee_rose_pitfalls/data_dpi/all_root_data.csv")
plot(rs$length, rs2$length)
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv") %>%
arrange(image, root)
rs2  <- read_csv("~/Dropbox/science/outputs/papers/2018-mee_rose_pitfalls/data_dpi/all_root_data.csv") %>%
arrange(image, root)
plot(rs$length, rs2$length)
plot(rs$root, rs2$root)
plot(rs$root_order, rs2$root_order)
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv") %>%
arrange(image, root)
rs2  <- read_csv("~/Dropbox/science/outputs/papers/2018-mee_rose_pitfalls/data_dpi/all_root_data.csv") %>%
arrange(image, root)
merge(rs2, rs, by = "image")
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv") %>%
arrange(image, root)
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv")
rs2  <- read_csv("~/Dropbox/science/outputs/papers/2018-mee_rose_pitfalls/data_dpi/all_root_data.csv")
merge(rs2, rs, by = "image") %>%
write_csv("~/Dropbox/science/outputs/papers/2018-mee_rose_pitfalls/data_dpi/all_root_data.csv")
rs  <- read_csv("~/Desktop/root_data_dicot-2.csv") %>%
arrange(image)
rs2  <- read_csv("~/Dropbox/science/outputs/papers/2018-mee_rose_pitfalls/data_dpi/ground_truth_data.csv") %>%
arrange(image)
plot(rs$tot_root_length, rs2$tot_root_length)
rs %>%
filter(grepl("dicot-sim-1-1-80-15", image))
shiny::runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
runApp('Dropbox/science/projects/0_marshal/marshal')
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
dat1 <- data.frame(
sex = factor(c("Female","Female","Male","Male")),
time = factor(c("Lunch","Dinner","Lunch","Dinner"), levels=c("Lunch","Dinner")),
total_bill = c(13.53, 16.81, 16.24, 17.42)
)
p <- ggplot(data=dat1, aes(x=time, y=total_bill, group=sex, shape=sex)) +
geom_line() +
geom_point()
p
ggplotly(p)
p <- ggplot(data=dat1, aes(x=time, y=total_bill, group=sex, shape=sex)) +
geom_line() +
geom_point() +
theme_classic()
p
ggplotly(p)
p <- ggplot(data=dat1, aes(x=time, y=total_bill, group=sex, shape=sex)) +
geom_line(size=2) +
geom_point(size = 4) +
theme_classic()
p
ggplotly(p)
runApp()
runApp()
runApp()
